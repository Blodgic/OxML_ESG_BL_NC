{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d212444-4e68-4bd5-a8d3-55c61b7270c5",
   "metadata": {},
   "source": [
    "## 2 Text Cleaning for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1744212f-a99f-426e-8be6-1e99eacc98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text cleaning \n",
    "#reference:\n",
    "#https://machinelearningmastery.com/clean-text-machine-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a55a5467-3a60-41c2-8e31-713be804ff93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>report_519.pdf.53</td>\n",
       "      <td>governance</td>\n",
       "      <td>2021 ESG Impact Report                        ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>report_1537.pdf.24</td>\n",
       "      <td>social</td>\n",
       "      <td>24 2021 SUSTAINABILITY REPORT TABLE OF CONTENT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report_567.pdf.33</td>\n",
       "      <td>governance</td>\n",
       "      <td>Sustainability Governance Clean Harbors’ commi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>report_1830.pdf.220</td>\n",
       "      <td>other</td>\n",
       "      <td>220 Report of the réviseur d’entreprises agréé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>report_1253.pdf.46</td>\n",
       "      <td>governance</td>\n",
       "      <td>Pfizer 2021 ESG Report 46 Governance Governanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2409</th>\n",
       "      <td>LLM created</td>\n",
       "      <td>governance</td>\n",
       "      <td>Everyone in the organization has a role to pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2410</th>\n",
       "      <td>LLM created</td>\n",
       "      <td>governance</td>\n",
       "      <td>We aim to create a workplace where people feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>LLM created</td>\n",
       "      <td>governance</td>\n",
       "      <td>Our approach to corporate citizenship means gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>LLM created</td>\n",
       "      <td>governance</td>\n",
       "      <td>By building an open and inclusive corporate cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>LLM created</td>\n",
       "      <td>governance</td>\n",
       "      <td>Ultimately, our reputation hinges on our abili...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2414 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id       class  \\\n",
       "0       report_519.pdf.53  governance   \n",
       "1      report_1537.pdf.24      social   \n",
       "2       report_567.pdf.33  governance   \n",
       "3     report_1830.pdf.220       other   \n",
       "4      report_1253.pdf.46  governance   \n",
       "...                   ...         ...   \n",
       "2409          LLM created  governance   \n",
       "2410          LLM created  governance   \n",
       "2411          LLM created  governance   \n",
       "2412          LLM created  governance   \n",
       "2413          LLM created  governance   \n",
       "\n",
       "                                                   text  \n",
       "0     2021 ESG Impact Report                        ...  \n",
       "1     24 2021 SUSTAINABILITY REPORT TABLE OF CONTENT...  \n",
       "2     Sustainability Governance Clean Harbors’ commi...  \n",
       "3     220 Report of the réviseur d’entreprises agréé...  \n",
       "4     Pfizer 2021 ESG Report 46 Governance Governanc...  \n",
       "...                                                 ...  \n",
       "2409  Everyone in the organization has a role to pla...  \n",
       "2410  We aim to create a workplace where people feel...  \n",
       "2411  Our approach to corporate citizenship means gi...  \n",
       "2412  By building an open and inclusive corporate cu...  \n",
       "2413  Ultimately, our reputation hinges on our abili...  \n",
       "\n",
       "[2414 rows x 3 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #import clean training and hugging face chat LLM created training data\n",
    "import pandas as pd\n",
    "#ingest original training data with LLM created training data \n",
    "OG_df = pd.read_csv(r'Data/original_training_LLMcreated.csv')\n",
    "OG_df\n",
    "#df.id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038d8974-abbf-4eae-b41d-e8f8ab9b52da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2414\n"
     ]
    }
   ],
   "source": [
    "print(len(OG_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a461839-2ed4-466d-b457-f3727e5218aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of OG train\n",
      "1956\n",
      "new length\n",
      "2117\n"
     ]
    }
   ],
   "source": [
    "#import the training txt files, parse and append to a new df\n",
    "import pandas as pd \n",
    "# Get Hugging Face LLM created texts\n",
    "my_file = open('Data/oxml_esg_texts.txt', \"r\")\n",
    "data = my_file.read()\n",
    "texts = data.split(\"unique_linebreak\")\n",
    "my_file.close()\n",
    "\n",
    "# Get ESG labels\n",
    "df = pd.read_csv('Data/labels.csv')\n",
    "print(\"length of OG train\")\n",
    "print(len(df))\n",
    "\n",
    "labels = {\n",
    "    'governance': 0,\n",
    "    'social': 1,\n",
    "    'environmental': 2,\n",
    "    'other': 3\n",
    "}\n",
    "\n",
    "# Add text column to label dataframe\n",
    "df['text'] = texts[:-1]\n",
    "\n",
    "# ''' -------------------------------------------------------------------- '''\n",
    "\n",
    "\n",
    "\n",
    "# ''' -------------------------------------------------------------------- '''\n",
    "#start with empty dataframe\n",
    "import pandas as pd \n",
    "#df = pd.DataFrame()\n",
    "\n",
    "# # Get extra environmental texts\n",
    "my_file = open('Data/environment_trianingGPT4.txt', \"r\")\n",
    "data = my_file.read()\n",
    "env_texts = data.split(\"unique_linebreak\")\n",
    "my_file.close()\n",
    "\n",
    "# Create environmental labels for extra texts\n",
    "env_labels = ['environmental'] * len(env_texts)\n",
    "\n",
    "# Add extra environmental texts to working dataframe\n",
    "for i, j in zip(env_texts, env_labels):\n",
    "    df = df.append({'text': i, 'class': j}, ignore_index=True)\n",
    "\n",
    "''' -------------------------------------------------------------------- '''\n",
    "\n",
    "# Get extra social texts\n",
    "my_file = open('Data/social_trianingGPT3.txt', \"r\")\n",
    "data = my_file.read()\n",
    "social_texts = data.split(\"unique_linebreak\")\n",
    "my_file.close()\n",
    "\n",
    "# Create social labels for extra texts\n",
    "social_labels = ['social'] * len(social_texts)\n",
    "\n",
    "# Add extra social texts to working dataframe\n",
    "for i, j in zip(social_texts, social_labels):\n",
    "    df = df.append({'text': i, 'class': j}, ignore_index=True)\n",
    "\n",
    "''' -------------------------------------------------------------------- '''\n",
    "\n",
    "\n",
    "# # Get extra governance texts\n",
    "my_file = open('Data/governance_trianingGPT3.txt', \"r\")\n",
    "data = my_file.read()\n",
    "gov_texts = data.split(\"unique_linebreak\")\n",
    "my_file.close()\n",
    "\n",
    "# Create social labels for extra texts\n",
    "gov_labels = ['governance'] * len(gov_texts)\n",
    "\n",
    "# Add extra social texts to working dataframe\n",
    "for i, j in zip(gov_texts, gov_labels):\n",
    "    df = df.append({'text': i, 'class': j}, ignore_index=True)\n",
    "print(\"new length\")\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "765e73d2-36e2-4ba9-ab0e-95c6a00daba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create ID field \n",
    "df['id'] = 'GPT4All'\n",
    "#rearrange columns\n",
    "df = df[['id', 'class', 'text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d8f5eb6-73ef-402c-8b39-5ee02ddecb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4531\n"
     ]
    }
   ],
   "source": [
    "#append OG + LLM to new GPT4All data\n",
    "df_appended = OG_df.append(df)\n",
    "print(len(df_appended))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba1612-39b3-4402-94a5-0d2e7406e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2127071-fdf3-402c-ae9e-4f0ea05089e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4439\n"
     ]
    }
   ],
   "source": [
    "#remove duplicate text values \n",
    "df_appended = df_appended.drop_duplicates(subset=['text'], keep='first')\n",
    "print(len(df_appended))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f6f820-1d94-4044-a6ff-7e0c50edcd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ESG Impact Report                            ...\n",
       "1         SUSTAINABILITY REPORT TABLE OF CONTENTS SOCI...\n",
       "2       Sustainability Governance Clean Harbors’ commi...\n",
       "3        Report of the réviseur d’entreprises agréé • ...\n",
       "4       Pfizer  ESG Report  Governance Governance — Co...\n",
       "                              ...                        \n",
       "2111    In this report, we will analyze GPT's commitme...\n",
       "2112    In order to ensure successful implementation o...\n",
       "2113    I am pleased to provide you with this report a...\n",
       "2114    As an AI language model, I can generate  words...\n",
       "2115    I am pleased to present this report on XYZ Com...\n",
       "Name: text, Length: 4439, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove punctuation and \\n \n",
    "import re \n",
    "df = df_appended \n",
    "#df['text'] = df['text'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "\n",
    "# Match all digits in the string and replace them with an empty string\n",
    "df['text'] = df['text'].astype(str)\n",
    "df['text'] = df['text'].str.replace('\\d+', '')\n",
    "\n",
    "df['text'] = df['text'].str.replace('\\n', '')\n",
    "\n",
    "#lower\n",
    "#df['text'] = df['text'].str.lower()\n",
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33dc8798-3a5b-4baa-8d20-dfb7a0283044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ESG Impact Report Data privacy security and re...\n",
       "1       SUSTAINABILITY REPORT TABLE OF CONTENTS SOCIAL...\n",
       "2       Sustainability Governance Clean Harbors commit...\n",
       "3       Report of the réviseur d entreprises agréé Eva...\n",
       "4       Pfizer ESG Report Governance Governance Contin...\n",
       "                              ...                        \n",
       "2111    In this report we will analyze GPT commitment ...\n",
       "2112    In order to ensure successful implementation o...\n",
       "2113    I am pleased to provide you with this report a...\n",
       "2114    As an AI language model I can generate words o...\n",
       "2115    I am pleased to present this report on XYZ Com...\n",
       "Name: text, Length: 4439, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter Out non alpha numeric\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "# remove all tokens that are not alphabetic\n",
    "df['text'] = df['text'].astype(str)\n",
    "\n",
    "# Remove characters that are not letter or numbers\n",
    "# Define a function to remove non-alphanumeric tokens\n",
    "def remove_non_alphanumeric(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    alphanumeric_tokens = [token for token in tokens if token.isalnum()]\n",
    "    return ' '.join(alphanumeric_tokens)\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "df['text'] = df['text'].apply(remove_non_alphanumeric)\n",
    "df['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bc3e5ba-03ba-4253-b557-7db0a7c8cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize the PorterStemmer\n",
    "# from nltk.stem import PorterStemmer\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# stemmer = PorterStemmer()\n",
    "\n",
    "# # Define a function to perform stemming\n",
    "# def stem_words(text):\n",
    "#     tokens = word_tokenize(text)\n",
    "#     stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
    "#     return ' '.join(stemmed_tokens)\n",
    "\n",
    "# # Apply the function to the 'text' column\n",
    "# df['text'].apply(stem_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "163ad9fa-c767-44e7-a4e9-3057ac385f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Removing Contractions\n",
    "# #!pip install contractions\n",
    "# import contractions\n",
    "# df['text'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "\n",
    "\n",
    "# #Output\n",
    "# #she would like to know how I would do that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad1641c9-fc6f-4557-a639-5aff3885257c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /Users/Jupiter/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#upgrade nltk for lemmonization \n",
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a43ae255-25f9-44c2-9359-4bfda4849b16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Initialize the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Define a function to perform lemmatization\n",
    "def lemmatize_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Apply the function to the 'text' column\n",
    "df['text'] = df['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cdba465-4ea9-4968-b426-f349e8195f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ESG Impact Report Data privacy security reliab...\n",
       "1       SUSTAINABILITY REPORT TABLE OF CONTENTS SOCIAL...\n",
       "2       Sustainability Governance Clean Harbors commit...\n",
       "3       Report réviseur entreprises agréé Evaluate app...\n",
       "4       Pfizer ESG Report Governance Governance Contin...\n",
       "                              ...                        \n",
       "2111    In report analyze GPT commitment Environmental...\n",
       "2112    In order ensure successful implementation ESG ...\n",
       "2113    I pleased provide report Company X focus corpo...\n",
       "2114    As AI language model I generate word text base...\n",
       "2115    I pleased present report XYZ Company focus cor...\n",
       "Name: text, Length: 4439, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stopwords\n",
    "#remove stop words from content\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "final_stopwords_list = stopwords.words('english')\n",
    "# Exclude stopwords with Python's list comprehension and pandas.DataFrame.apply.\n",
    "df['text'] = df['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (final_stopwords_list)]))\n",
    "df['text'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34fa0fa2-0cc5-4d6e-a70b-49495dd96aca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2111</th>\n",
       "      <td>GPT4All</td>\n",
       "      <td>governance</td>\n",
       "      <td>In report analyze GPT commitment Environmental...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>GPT4All</td>\n",
       "      <td>governance</td>\n",
       "      <td>In order ensure successful implementation ESG ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>GPT4All</td>\n",
       "      <td>governance</td>\n",
       "      <td>I pleased provide report Company X focus corpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2114</th>\n",
       "      <td>GPT4All</td>\n",
       "      <td>governance</td>\n",
       "      <td>As AI language model I generate word text base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115</th>\n",
       "      <td>GPT4All</td>\n",
       "      <td>governance</td>\n",
       "      <td>I pleased present report XYZ Company focus cor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id       class                                               text\n",
       "2111  GPT4All  governance  In report analyze GPT commitment Environmental...\n",
       "2112  GPT4All  governance  In order ensure successful implementation ESG ...\n",
       "2113  GPT4All  governance  I pleased provide report Company X focus corpo...\n",
       "2114  GPT4All  governance  As AI language model I generate word text base...\n",
       "2115  GPT4All  governance  I pleased present report XYZ Company focus cor..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "709a5a1b-5809-4dea-a6ce-8c215ec92f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4439\n"
     ]
    }
   ],
   "source": [
    "#remove empty rows \n",
    "#df.dropna(subset=['text'], inplace=True)\n",
    "df = df.dropna(subset=['text'])\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3382f61f-d830-4089-8ef7-e563c7df8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop last empty row\n",
    "# df = df[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc6b2a-ddd4-48d6-97a8-5192acf2a07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine proportion of classes - they are uneven "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7f716d0-8be2-4882-bcc9-e9efd1b18f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other            0.400541\n",
       "social           0.280243\n",
       "environmental    0.170984\n",
       "governance       0.148232\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a48887ea-b4e2-499f-a7fa-6d7ae53f4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('Data/4463_clean_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f77e0d3e-0fe9-4115-ad0e-07b7330a6b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/site-packages (from imbalanced-learn) (1.1.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/site-packages (from imbalanced-learn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from imbalanced-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/Jupiter/Library/Python/3.9/lib/python/site-packages (from imbalanced-learn) (1.22.4)\n",
      "Installing collected packages: imbalanced-learn\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed imbalanced-learn-0.10.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.9 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#imbalance to balance class \n",
    "#https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/\n",
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eeea7f06-0cca-498d-baa3-03b6f1b1fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13ef7f15-297f-438b-926f-6978392039f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# check version number\n",
    "import imblearn\n",
    "print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3d1ad20-88e5-4fe4-9f7c-87c83d171298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "672665c0-dfb8-4ec4-a6ff-fc3db197cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "under = RandomUnderSampler(sampling_strategy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ead1a5ae-c741-4520-a600-f7e738e77b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3329 1110\n"
     ]
    }
   ],
   "source": [
    "#Split the data into train and test\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, shuffle=True)\n",
    "\n",
    "print(len(df_train), len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64f001ee-8bf6-4faf-b07c-7ba252051c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>GPT4All</td>\n",
       "      <td>other</td>\n",
       "      <td>REFERENCE DOCUMENT AIR LIQUIDE FINANCIAL STATE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>report_711.pdf.57</td>\n",
       "      <td>environmental</td>\n",
       "      <td>Diesel consumption kl Production kt Intensitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>GPT4All</td>\n",
       "      <td>other</td>\n",
       "      <td>contract asset liability satisfied life contra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>GPT4All</td>\n",
       "      <td>other</td>\n",
       "      <td>Audit Committee Oversight financial reporting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>GPT4All</td>\n",
       "      <td>environmental</td>\n",
       "      <td>Recycle Reusable Resources Program Our busines...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id          class  \\\n",
       "752             GPT4All          other   \n",
       "1480  report_711.pdf.57  environmental   \n",
       "833             GPT4All          other   \n",
       "292             GPT4All          other   \n",
       "638             GPT4All  environmental   \n",
       "\n",
       "                                                   text  \n",
       "752   REFERENCE DOCUMENT AIR LIQUIDE FINANCIAL STATE...  \n",
       "1480  Diesel consumption kl Production kt Intensitie...  \n",
       "833   contract asset liability satisfied life contra...  \n",
       "292   Audit Committee Oversight financial reporting ...  \n",
       "638   Recycle Reusable Resources Program Our busines...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2980ade7-f197-4ff7-9964-8754f66f32c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      id                                               text  \\\n",
      "0            LLM created  Sustainable mining involves identifying way ba...   \n",
      "1                GPT4All  Introduction Our Communities Our People Our En...   \n",
      "2     report_1404.pdf.20  DIAMONDBACK ENERGY CSR ENVIRONMENT E N V I R O...   \n",
      "3                GPT4All  Our environmental record Nevertheless believe ...   \n",
      "4      report_567.pdf.17  Recycle Reusable Resources Program Our busines...   \n",
      "...                  ...                                                ...   \n",
      "2627             GPT4All  COMMUNITY ACCO Brands Charitable Giving Commun...   \n",
      "2628   report_932.pdf.17  POLYMETAL EMPLOYEES Fatalities Severe injury M...   \n",
      "2629             GPT4All  Everything today ensures safer productive tomo...   \n",
      "2630             GPT4All  CASE STUDY area executive video Johan Meyer Ex...   \n",
      "2631         LLM created  Embracing pluralism foster broader representat...   \n",
      "\n",
      "              class  \n",
      "0     environmental  \n",
      "1     environmental  \n",
      "2     environmental  \n",
      "3     environmental  \n",
      "4     environmental  \n",
      "...             ...  \n",
      "2627         social  \n",
      "2628         social  \n",
      "2629         social  \n",
      "2630         social  \n",
      "2631         social  \n",
      "\n",
      "[2632 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#balance\n",
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Separate features and target variable\n",
    "X = df[['id', 'text']]\n",
    "y = df['class']\n",
    "\n",
    "# Create the RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Resample the data\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# Create a new balanced DataFrame\n",
    "df_balanced = pd.DataFrame(X_resampled, columns=['id', 'text'])\n",
    "df_balanced['class'] = y_resampled\n",
    "\n",
    "# Print the balanced DataFrame\n",
    "print(df_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "661b45f6-819b-45bb-9dc2-f7e501c871ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "environmental    658\n",
       "governance       658\n",
       "other            658\n",
       "social           658\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#an even set of classes for the training data\n",
    "df_balanced['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3cd742b-1907-4bde-bac4-979584eec190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_balanced.to_csv('training_balanced_cleaned.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
